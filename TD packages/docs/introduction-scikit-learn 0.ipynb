{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un didacticiel rapide de modélisation d'apprentissage automatique avec Python et Scikit-Learn\n",
    "\n",
    "Ce cahier passe en revue une gamme de fonctionnalités communes et utiles de la bibliothèque Scikit-Learn.\n",
    "\n",
    "Il y en a un tas ici, mais je l'appelle rapide en raison de l'étendue de la bibliothèque Scikit-Learn.\n",
    "\n",
    "Couvrir tout nécessite une [documentation complète](https://scikit-learn.org/stable/user_guide.html), dont, si jamais vous êtes bloqué, je vous recommande fortement de la consulter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-11-05 11:17:48.802806\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(f\"Last updated: {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pourquoi Scikit-Learn ?\n",
    "\n",
    "Bien que les domaines de la science des données et de l’apprentissage automatique soient vastes, l’objectif principal est de trouver des modèles au sein des données, puis de les utiliser pour faire des prédictions.\n",
    "\n",
    "Et il existe certaines catégories dans lesquelles appartiennent la majorité des problèmes.\n",
    "\n",
    "Si vous essayez de créer un modèle d'apprentissage automatique pour prédire si un e-mail est du spam ou non, vous travaillez sur un [problème de classification](https://en.wikipedia.org/wiki/Statistical_classification#Binary_and_multiclass_classification) (que quelque chose soit une chose ou une autre).\n",
    "\n",
    "Si vous essayez de créer un modèle d'apprentissage automatique pour prédire le prix des maisons en fonction de leurs caractéristiques, vous travaillez sur un [problème de régression](https://en.wikipedia.org/wiki/Regression_analysis) (prédire un certain nombre ).\n",
    "\n",
    "Si vous essayez d'obtenir qu'un algorithme d'apprentissage automatique regroupe des échantillons similaires (dont vous ne savez pas nécessairement lesquels doivent aller ensemble), vous travaillez sur un [problème de clustering](https://developers.google.com /apprentissage automatique/clustering/présentation).\n",
    "\n",
    "Une fois que vous savez sur quel type de problème vous travaillez, vous suivrez également des étapes similaires pour chacun. Des étapes telles que la division des données en différents ensembles, un sur lequel vos algorithmes d'apprentissage automatique peuvent apprendre (l'ensemble d'entraînement) et un autre pour les tester (l'ensemble de test).\n",
    "\n",
    "Choisir un modèle d'apprentissage automatique, puis évaluer si votre modèle a appris ou non quelque chose.\n",
    "\n",
    "Scikit-Learn propose des implémentations Python pour effectuer tous ces types de tâches (de la préparation des données à la modélisation des données). Vous évitant d'avoir à les créer à partir de zéro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Que couvre ce carnet ?\n",
    "\n",
    "La bibliothèque Scikit-Learn est très performante. Cependant, il n’est pas nécessaire de tout apprendre par cœur. Au lieu de cela, ce bloc-notes se concentre sur certains des principaux cas d'utilisation de la bibliothèque.\n",
    "\n",
    "Plus précisément, nous aborderons :\n",
    "\n",
    "<img src=\"../images/sklearn-workflow-title.png\" alt=\"un workflow scikit-learn en 6 étapes\"/>\n",
    "\n",
    "0. Un workflow Scikit-Learn de bout en bout\n",
    "1. Préparer les données\n",
    "2. Choisir le bon estimateur/aglorithme/modèle d'apprentissage automatique pour votre problème\n",
    "3. Ajuster le modèle d'apprentissage automatique que vous avez choisi aux données et l'utiliser pour faire une prédiction\n",
    "4. Évaluation d'un modèle d'apprentissage automatique\n",
    "5. Améliorer les prédictions grâce à l'expérimentation (réglage des hyperparamètres)\n",
    "6. Sauvegarde et chargement d'un modèle pré-entraîné\n",
    "7. Rassembler le tout dans un pipeline\n",
    "\n",
    "> **Remarque :** Toutes les étapes de ce cahier sont axées sur [**l'apprentissage supervisé**](https://en.wikipedia.org/wiki/Supervised_learning) (avoir des données et des étiquettes). L'autre aspect de l'apprentissage supervisé est [**l'apprentissage non supervisé**](https://en.wikipedia.org/wiki/Unsupervised_learning) (avoir des données mais pas d'étiquettes).\n",
    "\n",
    "Après l'avoir parcouru, vous aurez les connaissances de base de Scikit-Learn dont vous avez besoin pour continuer à avancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Où puis-je obtenir de l'aide ?\n",
    "\n",
    "Si vous êtes bloqué ou pensez à quelque chose que vous aimeriez faire et que ce carnet ne couvre pas, n'ayez crainte !\n",
    "\n",
    "Les étapes recommandées à suivre sont les suivantes :\n",
    "1. **Essayez-le** - Puisque Scikit-Learn a été conçu dans un souci de convivialité, votre première étape devrait être d'utiliser ce que vous savez et d'essayer de trouver la réponse à votre propre question (se tromper fait partie du processus ). En cas de doute, exécutez votre code.\n",
    "2. **Appuyez sur SHIFT+TAB** - Vous pouvez voir la docstring d'une fonction (informations sur ce que fait la fonction) en appuyant sur **SHIFT + TAB** à l'intérieur. Faire cela est une bonne habitude à développer. Cela améliorera vos compétences en recherche et vous donnera une meilleure compréhension de la bibliothèque.\n",
    "3. **Recherchez-le** - Si l'essayer par vous-même ne fonctionne pas, puisque quelqu'un d'autre a probablement essayé de faire quelque chose de similaire, essayez de rechercher votre problème. Vous vous retrouverez probablement dans l'un des deux endroits :\n",
    "     * [Documentation/guide de l'utilisateur Scikit-Learn](https://scikit-learn.org/stable/user_guide.html) - la ressource la plus complète que vous trouverez pour les informations sur Scikit-Learn.\n",
    "     * [Stack Overflow](https://stackoverflow.com/) - il s'agit du centre de questions et réponses des développeurs, il regorge de questions et de réponses sur différents problèmes sur un large éventail de sujets de développement logiciel et il y a de fortes chances qu'il y en ait un lié à votre problème. .\n",
    "     * [ChatGPT](https://chat.openai.com/) - ChatGPT est très efficace pour expliquer le code, cependant, il peut commettre des erreurs. Il est préférable de vérifier le code qu'il écrit avant de l'utiliser. Essayez de demander « Pouvez-vous m'expliquer le code suivant ? {votre code ici} », puis continuez avec les questions de suivi à partir de là.\n",
    "    \n",
    "Un exemple de recherche d'une solution Scikit-Learn pourrait être :\n",
    "\n",
    "> \"comment régler les hyperparamètres d'un modèle sklearn\"\n",
    "\n",
    "Une recherche sur Google mène à la documentation Scikit-Learn pour la fonction `GridSearchCV` : http://scikit-learn.org/stable/modules/grid_search.html\n",
    "\n",
    "Les prochaines étapes ici consistent à lire la documentation, à vérifier les exemples et à voir s'ils correspondent au problème que vous essayez de résoudre. Si c'est le cas, **réécrivez le code** en fonction de vos besoins, exécutez-le et voyez quels sont les résultats.\n",
    "\n",
    "4. **Demander de l'aide** - Si vous avez suivi les 3 étapes ci-dessus et que vous êtes toujours bloqué, vous souhaiterez peut-être poser votre question sur [Stack Overflow](https://www.stackoverflow.com) ou dans le canal ZTM Machine Learning et AI Discord. Soyez aussi précis que possible et fournissez des détails sur ce que vous avez essayé.\n",
    "\n",
    "N'oubliez pas que vous n'êtes pas obligé d'apprendre toutes les fonctions par cœur pour commencer.\n",
    "\n",
    "Le plus important est de se demander continuellement : « qu’est-ce que j’essaie de faire avec les données ? »\n",
    "\n",
    "Commencez par répondre à cette question, puis entraînez-vous à trouver le code qui le fait.\n",
    "\n",
    "Commençons.\n",
    "\n",
    "Nous allons d’abord importer les bibliothèques que nous avons utilisées précédemment.\n",
    "\n",
    "Nous vérifierons également la version de « sklearn » dont nous disposons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Scikit-Learn version: 1.0.1 (materials in this notebook require this version or newer).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "print(f\"Using Scikit-Learn version: {sklearn.__version__} (materials in this notebook require this version or newer).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Un workflow Scikit-Learn de bout en bout\n",
    "\n",
    "Avant d'entrer dans les détails, voyons rapidement à quoi pourrait ressembler un flux de travail Scikit-Learn de bout en bout.\n",
    "\n",
    "Une fois que nous aurons vu un flux de travail de bout en bout, nous approfondirons chaque étape un peu plus.\n",
    "\n",
    "Plus précisément, nous allons mettre en pratique les étapes suivantes :\n",
    "1. Préparer les données (diviser en fonctionnalités et étiquettes, préparer les étapes d'entraînement et de test)\n",
    "2. Choisir un modèle pour notre problème\n",
    "3. Ajustez le modèle aux données et utilisez-le pour faire une prédiction\n",
    "4. Évaluer le modèle\n",
    "5. Expérimentez pour vous améliorer\n",
    "6. Enregistrez un modèle pour que quelqu'un d'autre puisse l'utiliser\n",
    "\n",
    "> **Remarque :** La section suivante contient un peu d'informations, mais il s'agit d'un flux de travail de bout en bout. Nous allons le parcourir assez rapidement, mais nous le détaillerons davantage dans le reste du cahier. Et comme Scikit-Learn est une bibliothèque très vaste, capable de résoudre de nombreux problèmes, le flux de travail que nous utilisons n'est qu'un exemple de la façon dont vous pouvez l'utiliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux de travail du classificateur de forêt aléatoire pour classer les maladies cardiaques\n",
    "\n",
    "#### 1. Préparez les données\n",
    "\n",
    "À titre d'exemple d'ensemble de données, nous importerons « heart-disease.csv ».\n",
    "\n",
    "Ce fichier contient les dossiers médicaux anonymisés des patients et indique s'ils souffrent ou non d'une maladie cardiaque (il s'agit d'un problème de classification puisque nous essayons de prédire si quelque chose est une chose ou une autre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "heart_disease = pd.read_csv('../data/heart-disease.csv')\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, chaque ligne correspond à un patient différent et toutes les colonnes, à l'exception de « cible », correspondent à des caractéristiques différentes du patient.\n",
    "\n",
    "La colonne `target` indique si le patient a une maladie cardiaque (`target=1`) ou non (`target=0`), c'est notre colonne \"label\", la variable que nous allons essayer de prédire.\n",
    "\n",
    "Le reste des colonnes (souvent appelés fonctionnalités) est ce que nous utiliserons pour prédire la valeur « cible ».\n",
    "\n",
    "> **Remarque :** Il est courant d'enregistrer les fonctionnalités dans une variable « X » et les étiquettes dans une variable « y ». En pratique, nous aimerions utiliser les « X » (caractéristiques) pour construire un algorithme prédictif permettant de prédire les « y » (étiquettes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer X (toutes les colonnes de fonctionnalités)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "\n",
    "# Créer y (la colonne cible)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Vérifiez la tête des fonctionnalités DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: target, dtype: int64,\n",
       " 1    165\n",
       " 0    138\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifiez la tête et le nombre de valeurs des étiquettes\n",
    "y.head(), y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'une des pratiques les plus importantes en matière d'apprentissage automatique consiste à diviser les ensembles de données en ensembles de formation et de test.\n",
    "\n",
    "Comme dans, un modèle s'entraînera sur l'ensemble d'entraînement** pour apprendre des modèles, puis ces modèles pourront être **évalués sur l'ensemble de test**.\n",
    "\n",
    "Surtout, un modèle ne devrait **jamais** voir les données de test pendant l'entraînement.\n",
    "\n",
    "Cela équivaut à ce qu'un étudiant étudie le matériel de cours pendant le semestre (ensemble de formation) puis teste ses capacités à l'examen suivant (ensemble de tests).\n",
    "\n",
    "Scikit-learn fournit la méthode [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) pour diviser les ensembles de données en ensembles d'entraînement et de test.\n",
    "\n",
    "> **Remarque :** Il est courant d'utiliser une répartition 80/20, 70/30 ou 75/25 pour les données d'entraînement/test. Il existe également un troisième ensemble, appelé ensemble de validation (par exemple 70/15/15 pour la formation/validation/test) pour le réglage des hyperparamètres, mais pour l'instant, nous nous concentrerons sur les ensembles de formation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 13), (76, 13), (227,), (76,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divisez les données en ensembles de formation et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.25) # par défaut, train_test_split utilise 25 % des données pour l'ensemble de test\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Choisissez le modèle et les hyperparamètres\n",
    "\n",
    "Le choix d'un modèle dépend souvent du type de problème sur lequel vous travaillez.\n",
    "\n",
    "Par exemple, Scikit-Learn recommande différents modèles, que vous travailliez sur un problème de classification ou de régression.\n",
    "\n",
    "Vous pouvez voir une carte détaillant les [différents types d'options de modèle et de recommandations dans la documentation Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "Scikit-Learn fait référence aux modèles comme « estimateurs », cependant, ils sont souvent également appelés « modèle » ou « clf » (abréviation de classificateur).\n",
    "\n",
    "Les hyperparamètres d'un modèle sont des paramètres que vous pouvez modifier pour l'adapter à votre problème, un peu comme les boutons d'un four que vous pouvez régler pour cuisiner votre plat préféré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puisque nous travaillons sur un problème de classification, nous allons commencer par un RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir les hyperparamètres actuels d'un modèle avec la méthode [`get_params()`](https://scikit-learn.org/stable/developers/develop.html#get-params-and-set-params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher les hyperparamètres actuels\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous laisserons cela tel quel pour le moment, car les modèles Scikit-Learn ont généralement de bons paramètres par défaut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Ajustez le modèle aux données et utilisez-le pour faire une prédiction\n",
    "\n",
    "Ajuster un modèle à un ensemble de données implique de lui transmettre les données et de lui demander de comprendre les modèles.\n",
    "\n",
    "S'il existe des étiquettes (apprentissage supervisé), le modèle tente d'établir la relation entre les données et les étiquettes.\n",
    "\n",
    "S'il n'y a pas d'étiquettes (apprentissage non supervisé), le modèle essaie de trouver des modèles et de regrouper des échantillons similaires.\n",
    "\n",
    "La plupart des modèles Scikit-Learn ont le [`fit(X, y)`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit) méthode intégrée, où le paramètre « X » correspond aux fonctionnalités et le paramètre « y » correspond aux étiquettes.\n",
    "\n",
    "Dans notre cas, nous commençons par ajuster un modèle sur le fractionnement d'entraînement (`X_train`, `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser le modèle pour faire une prédiction\n",
    "\n",
    "L’intérêt de former un modèle d’apprentissage automatique est de l’utiliser pour faire une sorte de prédiction dans le futur.\n",
    "\n",
    "Une fois votre instance de modèle entraînée, vous pouvez utiliser le [`predict()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict ) méthode pour prédire une valeur cible étant donné un ensemble de fonctionnalités.\n",
    "\n",
    "En d’autres termes, utilisez le modèle, ainsi que de nouvelles données invisibles et non étiquetées pour prédire l’étiquette.\n",
    "\n",
    "> **Remarque :** Les données sur lesquelles vous prédisez doivent avoir la même forme et le même format que les données sur lesquelles vous avez effectué votre entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/PycharmProjects/machine_learning_course/venv/lib/python3.8/site-packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7q/5sn_ssd501gcz8xq_xyjv7gm0000gn/T/ipykernel_997/1196017340.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cela ne fonctionne pas... formes incorrectes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/machine_learning_course/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/machine_learning_course/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/machine_learning_course/venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    567\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    568\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/machine_learning_course/venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/machine_learning_course/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    762\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Cela ne fonctionne pas... formes incorrectes\n",
    "y_label = clf.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque notre modèle a été entraîné sur les données de « X_train », les prédictions doivent être faites sur des données dans le même format et la même forme que « X_train ».\n",
    "\n",
    "Notre objectif dans de nombreux problèmes d'apprentissage automatique est d'utiliser des modèles appris à partir des données d'entraînement pour faire des prédictions sur les données de test (ou de futures données invisibles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "19    69    0   3       140   239    0        1      151      0      1.8   \n",
       "73    51    1   0       140   261    0        0      186      1      0.0   \n",
       "198   62    1   0       120   267    0        1       99      1      1.8   \n",
       "104   50    1   2       129   196    0        1      163      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "63       1   0     1  \n",
       "19       2   2     2  \n",
       "73       2   0     2  \n",
       "198      1   2     3  \n",
       "104      2   0     2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afin de prédire une étiquette, les données doivent avoir la même forme que X_train\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser le modèle pour faire une prédiction sur les données de test (évaluation plus approfondie)\n",
    "y_preds = clf.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Évaluer le modèle\n",
    "\n",
    "Maintenant que nous avons fait quelques prédictions, nous pouvons commencer à utiliser d'autres méthodes Scikit-Learn pour déterminer la qualité de notre modèle.\n",
    "\n",
    "Chaque modèle ou estimateur a une méthode intégrée [`score()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.score) .\n",
    "\n",
    "Cette méthode compare la capacité du modèle à apprendre les modèles entre les caractéristiques et les étiquettes.\n",
    "\n",
    "La méthode `score()` pour chaque modèle utilise une métrique d'évaluation standard pour mesurer les résultats de votre modèle.\n",
    "\n",
    "Dans le cas d'un classificateur (notre modèle), l'une des métriques d'évaluation les plus courantes est la [précision](https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score) (la fraction de la valeur correcte prédictions sur les prédictions totales).\n",
    "\n",
    "Vérifions la précision de notre modèle sur l'ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy on the training dataset is: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle sur l'ensemble d'entraînement\n",
    "train_acc = clf.score(X=X_train, y=y_train)\n",
    "print(f\"The model's accuracy on the training dataset is: {train_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waouh ! On dirait que notre modèle fonctionne plutôt bien sur l'ensemble de données d'entraînement.\n",
    "En effet, il a la possibilité de voir à la fois les données *et* les étiquettes.\n",
    "Qu’en est-il de l’ensemble de données de test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy on the testing dataset is: 88.16%\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle sur l'ensemble de test\n",
    "test_acc = clf.score(X=X_test, y=y_test)\n",
    "print(f\"The model's accuracy on the testing dataset is: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, il semble que la précision de notre modèle soit un peu moindre sur l'ensemble de données de test que sur l'ensemble de données d'entraînement.\n",
    "\n",
    "C'est assez souvent le cas, car rappelez-vous qu'un modèle n'a jamais vu les exemples de test auparavant.\n",
    "\n",
    "Il existe également un certain nombre d'autres méthodes d'évaluation que nous pouvons utiliser pour nos modèles de classification.\n",
    "\n",
    "Toutes les métriques de classification suivantes proviennent du module [`sklearn.metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics) :\n",
    "* [`classification_report(y_true, y_true)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report) - Crée un rapport texte montrant diverses classifications des métriques telles que [précision, rappel](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html) et le score F1.\n",
    "* [`confusion_matrix(y_true, y_pred)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) - Créer une [matrice de confusion]( https://en.wikipedia.org/wiki/Confusion_matrix) pour comparer les prédictions aux étiquettes de vérité.\n",
    "* [`accuracy_score(y_true, y_pred)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) - Recherchez le score de précision (le score par défaut métrique) pour un classificateur.\n",
    "\n",
    "Toutes les métriques ont ce qui suit en commun : elles comparent les prédictions d'un modèle (`y_pred`) aux étiquettes de vérité (`y_true`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        36\n",
      "           1       0.86      0.93      0.89        40\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.88      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Créer un rapport de classement\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30,  6],\n",
       "       [ 3, 37]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Créer une matrice de confusion\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.881578947368421"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculer le score de précision (identique à la méthode score() pour les classificateurs)\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Expérimenter pour améliorer\n",
    "\n",
    "Le premier modèle que vous créez est souvent appelé référence (une référence est souvent encore plus simple que le modèle que nous avons utilisé, une référence pourrait être \"prédisons simplement par défaut la valeur la plus courante et essayons ensuite de l'améliorer\").\n",
    "\n",
    "Une fois que vous avez un modèle de base, comme celui que nous avons ici, il est important de se rappeler que ce n'est souvent pas le modèle final que vous utiliserez.\n",
    "\n",
    "La prochaine étape du flux de travail consiste à essayer d'améliorer votre modèle de base.\n",
    "\n",
    "Comment?\n",
    "\n",
    "Avec l’une des devises les plus importantes de l’apprentissage automatique…\n",
    "\n",
    "*Expérimentez, expérimentez, expérimentez !*\n",
    "\n",
    "Les expériences peuvent prendre de nombreuses formes différentes.\n",
    "\n",
    "Mais divisons-le en deux.\n",
    "\n",
    "1. Du point de vue du modèle.\n",
    "2. Du point de vue des données.\n",
    "\n",
    "Du point de vue du modèle, cela peut impliquer des choses telles que l'utilisation d'un modèle plus complexe ou le réglage des hyperparamètres de votre modèle.\n",
    "\n",
    "Du point de vue des données, cela peut impliquer de collecter plus de données ou des données de meilleure qualité afin que votre modèle existant ait plus de chances d'apprendre les modèles qu'il contient.\n",
    "\n",
    "Si vous travaillez déjà sur un ensemble de données existant, il est souvent plus facile d'essayer d'abord une série d'expériences en perspective de modèle, puis de vous tourner vers des expériences en perspective de données si vous n'obtenez pas les résultats que vous recherchez.\n",
    "\n",
    "Une chose dont vous devez être conscient est que si vous ajustez les hyperparamètres d'un modèle dans une série d'expériences, vos résultats doivent toujours être validés de manière croisée (nous verrons cela plus tard !).\n",
    "\n",
    "La [validation croisée](http://scikit-learn.org/stable/modules/cross_validation.html) est un moyen de garantir que les résultats que vous obtenez sont cohérents dans vos ensembles de données de formation et de test (car il utilise plusieurs versions) des ensembles de formation et de test) plutôt que de la chance en raison de l'ordre dans lequel les ensembles de formation et de test d'origine ont été créés.\n",
    "\n",
    "* Essayez différents hyperparamètres.\n",
    "* Tous les différents paramètres doivent être validés de manière croisée.\n",
    "     * **Remarque :** Méfiez-vous de la validation croisée pour les problèmes de séries chronologiques (comme pour les séries chronologiques, vous ne voulez pas mélanger des échantillons du futur avec des échantillons du passé).\n",
    "    \n",
    "Les différents modèles que vous utilisez auront différents hyperparamètres que vous pourrez régler.\n",
    "\n",
    "Pour le cas de notre modèle, le [`RandomForestClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), nous allons commencer à essayer différentes valeurs pour ` n_estimators` (une mesure du nombre d'arbres dans la forêt aléatoire).\n",
    "\n",
    "Par défaut, « n_estimators=100 », alors que diriez-vous d'essayer les valeurs de « 100 » à « 200 » et de voir ce qui se passe (en général, plus c'est mieux) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 100 estimators...\n",
      "Model accuracy on test set: 86.84%\n",
      "\n",
      "Trying model with 110 estimators...\n",
      "Model accuracy on test set: 88.16%\n",
      "\n",
      "Trying model with 120 estimators...\n",
      "Model accuracy on test set: 86.84%\n",
      "\n",
      "Trying model with 130 estimators...\n",
      "Model accuracy on test set: 88.16%\n",
      "\n",
      "Trying model with 140 estimators...\n",
      "Model accuracy on test set: 88.16%\n",
      "\n",
      "Trying model with 150 estimators...\n",
      "Model accuracy on test set: 88.16%\n",
      "\n",
      "Trying model with 160 estimators...\n",
      "Model accuracy on test set: 86.84%\n",
      "\n",
      "Trying model with 170 estimators...\n",
      "Model accuracy on test set: 88.16%\n",
      "\n",
      "Trying model with 180 estimators...\n",
      "Model accuracy on test set: 86.84%\n",
      "\n",
      "Trying model with 190 estimators...\n",
      "Model accuracy on test set: 86.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Essayez différents nombres d'estimateurs (arbres)... (pas de validation croisée)\n",
    "np.random.seed(42)\n",
    "for i in range(100, 200, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {model.score(X_test, y_test) * 100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les mesures ci-dessus ont été mesurées sur un seul train et une division de test.\n",
    "\n",
    "Utilisons [`sklearn.model_selection.cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) pour mesurer les résultats sur 5 ensembles d'entraînement et de test différents.\n",
    "\n",
    "Nous pouvons y parvenir en définissant `cross_val_score(X, y, cv=5)`.\n",
    "\n",
    "Où `X` est l'ensemble de fonctionnalités *complet* et `y` est l'ensemble d'étiquettes *complet* et `cv` est le nombre de fractionnements d'entraînement et de test que `cross_val_score` créera automatiquement à partir des données (dans notre cas, `5 ` différentes divisions, c'est ce qu'on appelle la validation croisée 5 fois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying model with 100 estimators...\n",
      "Model accuracy on single test set split: 86.84%\n",
      "5-fold cross-validation score: 82.15%\n",
      "\n",
      "Trying model with 110 estimators...\n",
      "Model accuracy on single test set split: 88.16%\n",
      "5-fold cross-validation score: 81.17%\n",
      "\n",
      "Trying model with 120 estimators...\n",
      "Model accuracy on single test set split: 85.53%\n",
      "5-fold cross-validation score: 83.16%\n",
      "\n",
      "Trying model with 130 estimators...\n",
      "Model accuracy on single test set split: 86.84%\n",
      "5-fold cross-validation score: 83.14%\n",
      "\n",
      "Trying model with 140 estimators...\n",
      "Model accuracy on single test set split: 86.84%\n",
      "5-fold cross-validation score: 82.48%\n",
      "\n",
      "Trying model with 150 estimators...\n",
      "Model accuracy on single test set split: 85.53%\n",
      "5-fold cross-validation score: 80.17%\n",
      "\n",
      "Trying model with 160 estimators...\n",
      "Model accuracy on single test set split: 88.16%\n",
      "5-fold cross-validation score: 80.83%\n",
      "\n",
      "Trying model with 170 estimators...\n",
      "Model accuracy on single test set split: 88.16%\n",
      "5-fold cross-validation score: 81.83%\n",
      "\n",
      "Trying model with 180 estimators...\n",
      "Model accuracy on single test set split: 88.16%\n",
      "5-fold cross-validation score: 81.50%\n",
      "\n",
      "Trying model with 190 estimators...\n",
      "Model accuracy on single test set split: 88.16%\n",
      "5-fold cross-validation score: 81.83%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Avec validation croisée\n",
    "np.random.seed(42)\n",
    "for i in range(100, 200, 10):\n",
    "    print(f\"Trying model with {i} estimators...\")\n",
    "    model = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "\n",
    "    # Mesurer le score du modèle sur une seule répartition train/test\n",
    "    model_score = model.score(X_test, y_test)\n",
    "    print(f\"Model accuracy on single test set split: {model_score * 100:.2f}%\")\n",
    "    \n",
    "    # Mesurez le score moyen de validation croisée sur 5 divisions de train et de test différentes\n",
    "    cross_val_mean = np.mean(cross_val_score(model, X, y, cv=5))\n",
    "    print(f\"5-fold cross-validation score: {cross_val_mean * 100:.2f}%\")\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel modèle a obtenu le meilleur score de validation croisée ?\n",
    "\n",
    "Il s’agit généralement d’un meilleur indicateur d’un modèle de qualité qu’un score de précision unique.\n",
    "\n",
    "Plutôt que de configurer et de suivre manuellement les résultats de ces expériences, nous pouvons demander à Scikit-Learn d'effectuer l'exploration à notre place.\n",
    "\n",
    "[`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) de Scikit-Learn est un moyen de rechercher sur un ensemble de valeurs d'hyperparamètres différentes et suivre automatiquement ceux qui fonctionnent le mieux.\n",
    "\n",
    "Testons-le !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "The best parameter values are: {'n_estimators': 120}\n",
      "With a score of: 82.82%\n"
     ]
    }
   ],
   "source": [
    "# Une autre façon de le faire avec GridSearchCV...\n",
    "np.random.seed(42)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les paramètres à rechercher sous forme de dictionnaire\n",
    "# (il peut s'agir de n'importe lequel des hyperparamètres de votre modèle cible)\n",
    "param_grid = {'n_estimators': [i for i in range(100, 200, 10)]}\n",
    "\n",
    "# Configurer la recherche de grille\n",
    "grid = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                    param_grid=param_grid,\n",
    "                    cv=5,\n",
    "                    verbose=1) \n",
    "\n",
    "# Ajuster la recherche de grille aux données\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Trouver les meilleurs paramètres\n",
    "print(f\"The best parameter values are: {grid.best_params_}\")\n",
    "print(f\"With a score of: {grid.best_score_*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons extraire le meilleur attribut `best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=120)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir le modèle pour qu'il soit le meilleur estimateur\n",
    "clf = grid.best_estimator_\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant que nous avons le meilleur modèle à validation croisée, nous pouvons l'adapter et l'évaluer sur notre répartition originale train/test unique des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score on single split of the data: 88.16%\n"
     ]
    }
   ],
   "source": [
    "# Ajuster le meilleur modèle\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Trouvez les meilleurs scores de modèle sur notre division de test unique\n",
    "# (remarque : cela peut être inférieur au score de validation croisée puisqu'il ne concerne qu'une seule division des données)\n",
    "print(f\"Best model score on single split of the data: {clf.score(X_test, y_test)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Enregistrez un modèle pour que quelqu'un d'autre puisse l'utiliser\n",
    "\n",
    "Lorsque vous avez effectué quelques expériences et que vous êtes satisfait du fonctionnement de votre modèle, vous souhaiterez probablement que quelqu'un d'autre puisse l'utiliser.\n",
    "\n",
    "Cela peut prendre la forme d'un coéquipier ou d'un collègue essayant de reproduire et de valider vos résultats ou d'un client utilisant votre modèle dans le cadre d'un service ou d'une application que vous proposez.\n",
    "\n",
    "Enregistrer un modèle vous permet également de le réutiliser ultérieurement sans avoir à le recycler. Ce qui est utile, surtout lorsque vos temps d’entraînement commencent à augmenter.\n",
    "\n",
    "Vous pouvez [enregistrer un modèle Scikit-Learn](https://scikit-learn.org/stable/model_persistence.html) à l'aide du [module`pickle` intégré à Python](https://docs.python.org/3 /bibliothèque/pickle.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Enregistrer un modèle existant dans un fichier\n",
    "pickle.dump(model, open(\"random_forest_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickle model prediction score: 88.16%\n"
     ]
    }
   ],
   "source": [
    "# Chargez un modèle de cornichon enregistré et évaluez-le\n",
    "loaded_pickle_model = pickle.load(open(\"random_forest_model_1.pkl\", \"rb\"))\n",
    "print(f\"Loaded pickle model prediction score: {loaded_pickle_model.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les modèles plus grands, il peut être plus efficace d'utiliser [Joblib](https://joblib.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model_1.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Enregistrer un modèle en utilisant joblib\n",
    "dump(model, \"random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded joblib model prediction score: 88.16%\n"
     ]
    }
   ],
   "source": [
    "# Chargez un modèle joblib enregistré et évaluez-le\n",
    "loaded_joblib_model = load(\"random_forest_model_1.joblib\")\n",
    "print(f\"Loaded joblib model prediction score: {loaded_joblib_model.score(X_test, y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons parcouru beaucoup de terrain rapidement...\n",
    "\n",
    "Décomposons les choses un peu plus en revisitant chaque section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c556f6eb84b27a92005489cdcf9c9b80cc62ee891441f20eabfc5ad7282165a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
