{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenez l'ensemble de données sur le logement en Californie\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "housing; # est téléchargé sous forme de dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(housing[\"data\"], columns=housing[\"feature_names\"])\n",
    "housing_df[\"target\"] = pd.Series(housing[\"target\"])\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Améliorer les prédictions du modèle grâce à l'expérimentation (réglage des hyperparamètres)\n",
    "\n",
    "Les premières prédictions que vous effectuez avec un modèle sont généralement appelées **prédictions de base**.\n",
    "\n",
    "Il en va de même pour les premières mesures d’évaluation que vous obtenez. Celles-ci sont généralement appelées **métriques de base**.\n",
    "\n",
    "Votre prochain objectif est d'améliorer ces mesures de base.\n",
    "\n",
    "Comment?\n",
    "\n",
    "*Expérimentez, expérimentez, expérimentez !*\n",
    "\n",
    "Deux des principales méthodes pour améliorer les mesures de base sont :\n",
    "1. Du point de vue des données.\n",
    "2. Du point de vue du modèle.\n",
    "\n",
    "Du point de vue des données, la question suivante :\n",
    "* Pourrions-nous collecter plus de données ? En apprentissage automatique, il est généralement préférable d’avoir plus de données, car cela donne à un modèle plus de possibilités d’apprendre des modèles.\n",
    "* Pourrions-nous améliorer nos données ? Cela pourrait impliquer de combler des valeurs manquantes ou de trouver une meilleure stratégie d'encodage (transformer les données en chiffres).\n",
    "\n",
    "Du point de vue du modèle, demande :\n",
    "* Existe-t-il un meilleur modèle que nous pourrions utiliser ? Si vous avez commencé avec un modèle simple, pourriez-vous en utiliser un plus complexe ? (nous en avons vu un exemple en regardant la [carte d'apprentissage automatique Scikit-Learn](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), les méthodes d'ensemble sont généralement considérées comme des modèles plus complexes)\n",
    "* Pourrions-nous améliorer le modèle actuel ? Si le modèle que vous utilisez fonctionne bien dès la sortie de la boîte, les hyperparamètres peuvent-ils être ajustés pour le rendre encore meilleur ?\n",
    "\n",
    "> **Remarque :** Les modèles dans les données sont également souvent appelés paramètres de données. La différence entre les *paramètres* et les *hyperparamètres* est qu'un modèle d'apprentissage automatique cherche lui-même à trouver des paramètres dans les données, alors que les hyperparamètres sont des paramètres sur un modèle qu'une personne (vous) peut ajuster.\n",
    "\n",
    "Puisque nous disposons de deux ensembles de données existants, nous chercherons à améliorer nos résultats du point de vue du modèle.\n",
    "\n",
    "Plus précisément, nous verrons comment nous pourrions améliorer nos modèles `RandomForestClassifier` et `RandomForestRegressor` grâce au réglage des hyperparamètres.\n",
    "\n",
    "Que sont les hyperparamètres ?\n",
    "\n",
    "Bonne question, vérifions-les.\n",
    "\n",
    "Tout d'abord, nous allons instancier un `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque nous instancions un modèle comme ci-dessus, nous utilisons les hyperparamètres par défaut.\n",
    "\n",
    "Ceux-ci sont imprimés lorsque vous appelez l'instance de modèle et `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous verrez des choses comme `max_degree`, `min_samples_split`, `n_estimators`.\n",
    "\n",
    "Chacun d'entre eux est un hyperparamètre du « RandomForestClassifier » que vous pouvez ajuster.\n",
    "\n",
    "Vous pouvez considérer les hyperparamètres comme étant similaires aux cadrans d’un four.\n",
    "\n",
    "Avec le réglage par défaut, votre four peut faire un bon travail en cuisinant votre plat préféré. Mais avec un peu d’expérimentation, vous constaterez que les résultats sont meilleurs lorsque vous ajustez les paramètres.\n",
    "\n",
    "<img src=\"../docs/images/sklearn-hyperparameter-tuning-oven.png\" width=500/>\n",
    "\n",
    "Il en va de même pour l’amélioration d’un modèle d’apprentissage automatique par réglage d’hyperparamètres.\n",
    "\n",
    "Les hyperparamètres par défaut d'un modèle d'apprentissage automatique peuvent bien trouver des modèles dans les données. Mais il est possible qu'un ajustement des hyperparamètres améliore les performances d'un modèle.\n",
    "\n",
    "Chaque modèle d'apprentissage automatique aura différents hyperparamètres que vous pourrez régler.\n",
    "\n",
    "Vous vous demandez peut-être : « Comment puis-je me souvenir de tout cela ? »\n",
    "\n",
    "Une autre bonne question.\n",
    "\n",
    "C'est pourquoi nous nous concentrons sur Random Forest.\n",
    "\n",
    "Au lieu de mémoriser tous les hyperparamètres de chaque modèle, nous verrons comment procéder avec un seul.\n",
    "\n",
    "Et puis connaissant ces principes, vous pouvez les appliquer à un modèle différent si nécessaire.\n",
    "\n",
    "En lisant la [documentation Scikit-Learn pour Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), vous constaterez qu'ils suggèrent d'essayer de changer `n_estimators` (le nombre d'arbres dans la forêt) et `min_samples_split` (le nombre minimum d'échantillons requis pour diviser un nœud interne).\n",
    "\n",
    "Nous allons essayer de les régler ainsi que :\n",
    "* `max_features` (le nombre de fonctionnalités à prendre en compte lors de la recherche du meilleur partage)\n",
    "* `max_degree` (la profondeur maximale de l'arbre)\n",
    "* `min_samples_leaf` (le nombre minimum d'échantillons requis pour être sur un nœud feuille)\n",
    "\n",
    "Si cela semble encore beaucoup, la bonne nouvelle est que le processus que nous suivons avec Random Forest et ajustons ses hyperparamètres peut être utilisé pour d'autres modèles d'apprentissage automatique dans Scikit-Learn. La seule différence est qu'avec un modèle différent, les hyperparamètres que vous réglez seront différents.\n",
    "\n",
    "L'ajustement des hyperparamètres est généralement un processus expérimental pour déterminer lesquels sont les meilleurs. Car il n’existe aucun moyen réel de savoir quels hyperparamètres seront les meilleurs au début.\n",
    "\n",
    "Pour nous familiariser avec le réglage des hyparamètres, nous prendrons notre RandomForestClassifier et ajusterons ses hyperparamètres de 3 manières.\n",
    "\n",
    "1. À la main\n",
    "2. Au hasard avec [`sklearn.model_selection.RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "3. De manière exhaustive avec [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Réglage manuel des hyperparamètres\n",
    "\n",
    "Jusqu'à présent, nous avons travaillé avec des ensembles de données de formation et de test.\n",
    "\n",
    "Vous entraînez un modèle sur un ensemble d’entraînement et l’évaluez sur un ensemble de données de test.\n",
    "\n",
    "Mais le réglage des hyperparamètres introduit un troisième ensemble, un ensemble de validation.\n",
    "\n",
    "Le processus devient maintenant :\n",
    "1. Entraînez un modèle sur les données d'entraînement.\n",
    "2. (Essayez d') améliorer les hyperparamètres du modèle sur l'ensemble de validation.\n",
    "3. Évaluez le modèle sur l'ensemble de test.\n",
    "\n",
    "Si notre ensemble de données de départ contenait 100 étiquettes de dossiers de patients différents indiquant qui souffrait d'une maladie cardiaque et qui n'en souffrait pas et que nous souhaitions créer un modèle d'apprentissage automatique pour prédire qui souffrait d'une maladie cardiaque et qui n'en souffrait pas, cela pourrait ressembler à ceci :\n",
    "\n",
    "<img src=\"../docs/images/sklearn-train-valid-test-annotated.png\" width=500/>\n",
    "\n",
    "Puisque nous savons que nous utilisons un `RandomForestClassifier` et que nous connaissons les hyperparamètres que nous voulons ajuster, voyons à quoi cela ressemble.\n",
    "\n",
    "Tout d’abord, rappelons les paramètres de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et nous allons ajuster :\n",
    "* `max_profondeur`\n",
    "* `max_features`\n",
    "* `min_samples_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimateurs`\n",
    "\n",
    "Nous utiliserons le même code que précédemment, sauf que cette fois nous créerons une répartition formation, validation et test.\n",
    "\n",
    "Avec l'ensemble d'entraînement contenant 70 % des données et les ensembles de validation et de test contenant chacun 15 %.\n",
    "\n",
    "Obtenons quelques résultats de base, puis nous ajusterons le modèle.\n",
    "\n",
    "Et puisque nous allons évaluer quelques modèles, créons une fonction d'évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true: np.array, \n",
    "                   y_preds: np.array) -> dict:\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels.\n",
    "\n",
    "    Returns several metrics in the form of a dictionary.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2), \n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recréons maintenant un workflow précédent, sauf que nous ajouterons la création d'un ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 80.00%\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1 score: 0.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.78, 'recall': 0.88, 'f1': 0.82}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Définir la graine\n",
    "np.random.seed(42)\n",
    "\n",
    "# Lire les données\n",
    "heart_disease = pd.read_csv(\"../data/heart-disease.csv\")\n",
    "\n",
    "# Divisé en X (features) & y (labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Répartition formation et tests (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Créer une validation et une répartition des tests en divisant les données de test en deux (30 % de test -> 15 % de validation, 15 % de test)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Faites des prédictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluez le classificateur\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 212 samples, 212 labels\n",
      "Validation data: 45 samples, 45 labels\n",
      "Testing data: 46 samples, 46 labels\n"
     ]
    }
   ],
   "source": [
    "# Vérifiez les tailles des divisions\n",
    "print(f\"Training data: {len(X_train)} samples, {len(y_train)} labels\")\n",
    "print(f\"Validation data: {len(X_valid)} samples, {len(y_valid)} labels\")\n",
    "print(f\"Testing data: {len(X_test)} samples, {len(y_test)} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnifique, essayons maintenant d'améliorer les résultats.\n",
    "\n",
    "Nous allons changer 1 des hyperparamètres, `n_estimators=100` (par défaut) en `n_estimators=200` et voir si cela améliore l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 77.78%\n",
      "Precision: 0.77\n",
      "Recall: 0.83\n",
      "F1 score: 0.80\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Créer un deuxième classificateur\n",
    "clf_2 = RandomForestClassifier(n_estimators=200)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Faites des prédictions\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "# Évaluer le 2ème classificateur\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, il semble que doubler la valeur de « n_estimators » soit *pire* que la valeur par défaut, peut-être y a-t-il une meilleure valeur pour « n_estimators » ?\n",
    "\n",
    "Et quels autres hyperparamètres pourrions-nous modifier ?\n",
    "\n",
    "Attendez...\n",
    "\n",
    "Cela pourrait prendre un certain temps si nous ne faisons que créer de nouveaux modèles avec de nouveaux hyperparamètres à chaque fois.\n",
    "\n",
    "Il existe sûrement un meilleur moyen ?\n",
    "\n",
    "Il y a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Réglage des hyperparamètres avec [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "[`sklearn.model_selection.RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) de Scikit-Learn nous permet de rechercher aléatoirement différents hyperparamètres pour voir lesquels fonctionnent le mieux. .\n",
    "\n",
    "Il stocke également des détails sur ceux qui fonctionnent le mieux !\n",
    "\n",
    "Voyons-le en action.\n",
    "\n",
    "Tout d’abord, nous créons un dictionnaire de distributions de paramètres (collections de différentes valeurs pour des hyperparamètres spécifiques) que nous aimerions parcourir.\n",
    "\n",
    "Ce dictionnaire se présente sous la forme :\n",
    "\n",
    "```python\n",
    "param_distributions = {\"hyperparameter_name\": [values_to_randomly_try]}\n",
    "```\n",
    "\n",
    "Où `\"hyperparameter_name\"` est la valeur d'un hyperparamètre spécifique pour un modèle et `[values_to_randomly_try]` est une liste de valeurs pour cet hyperparamètre spécifique à essayer de manière aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grille d'hyperparamètres RandomizedSearchCV recherchera\n",
    "param_distributions = {\"n_estimators\": [10, 100, 200, 500, 1000, 1200],\n",
    "                       \"max_depth\": [None, 5, 10, 20, 30],\n",
    "                       \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "                       \"min_samples_split\": [2, 4, 6, 8],\n",
    "                       \"min_samples_leaf\": [1, 2, 4, 8]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D’où viennent ces valeurs ?\n",
    "\n",
    "Ils sont inventés.\n",
    "\n",
    "Composé?\n",
    "\n",
    "Oui.\n",
    "\n",
    "Pas complètement sorti de l'air, mais après avoir lu la [documentation Scikit-Learn sur Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), vous en verrez de ces valeurs ont certaines valeurs qui fonctionnent généralement bien et certains hyperparamètres acceptent des chaînes plutôt que des entiers.\n",
    "\n",
    "Maintenant que nous avons la configuration du dictionnaire de distribution des paramètres, « RandomizedSearchCV » de Scikit-Learn l'examinera, choisira une valeur aléatoire parmi chacune, instanciera un modèle avec ces valeurs et testera chaque modèle.\n",
    "\n",
    "Combien de modèles va-t-il tester ?\n",
    "\n",
    "Autant qu’il y en a pour chaque combinaison d’hyperparamètres à tester. Additionnons-les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1440 potential combinations of hyperparameters to test.\n"
     ]
    }
   ],
   "source": [
    "# Comptez le nombre total de combinaisons d'hyperparamètres à tester\n",
    "total_randomized_hyperparameter_combintions_to_test = np.prod([len(value) for value in param_distributions.values()])\n",
    "print(f\"There are {total_randomized_hyperparameter_combintions_to_test} potential combinations of hyperparameters to test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela fait beaucoup de combinaisons !\n",
    "\n",
    "Ou...\n",
    "\n",
    "Nous pouvons définir le paramètre `n_iter` pour limiter le nombre de tests de modèles `RandomizedSearchCV` (par exemple, `n_iter=20` signifie essayer `20` combinaisons aléatoires différentes d'hyperparamètres et validera de manière croisée chaque ensemble, donc si `cv=5 `, 5x20 = 100 ajustements au total).\n",
    "\n",
    "La meilleure chose?\n",
    "\n",
    "Les résultats que nous obtiendrons seront validés de manière croisée (d'où le CV dans `RandomizedSearchCV`) afin que nous puissions utiliser `train_test_split()`.\n",
    "\n",
    "Et comme nous examinons tant de modèles différents, nous définirons `n_jobs=-1` dans notre [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble. RandomForestClassifier.html) afin que Scikit-Learn profite de tous les cœurs (processeurs) de nos ordinateurs.\n",
    "\n",
    "Voyons-le en action.\n",
    "\n",
    "> **Remarque :** En fonction de `n_iter` (le nombre de modèles que vous testez), des différentes valeurs de la grille d'hyperparamètres et de la puissance de votre ordinateur, l'exécution de la cellule ci-dessous peut prendre un certain temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=8, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=8, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=8, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=8, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=8, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200; total time=   2.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   2.4s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   2.7s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=4, min_samples_split=4, n_estimators=1200; total time=   3.0s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=2, min_samples_split=8, n_estimators=1200; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=4, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=5, max_features=None, min_samples_leaf=1, min_samples_split=6, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=6, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=1, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=None, min_samples_leaf=8, min_samples_split=4, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=10; total time=   0.1s\n",
      "[INFO] Total time taken for 30 random combinations of hyperparameters: 114.83 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Démarrer le chronomètre\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Divisez en X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Divisez en ensembles de train et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Définissez n_jobs sur -1 pour utiliser tous les cœurs disponibles sur votre machine (si cela provoque des erreurs, essayez n_jobs=1)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Configurer RandomizedSearchCV\n",
    "n_iter = 30 # essayez 30 modèles\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                            param_distributions=param_distributions,\n",
    "                            n_iter=n_iter, \n",
    "                            cv=5, # 5-fold cross-validation\n",
    "                            verbose=2) # affiche les résultats\n",
    "\n",
    "# Ajuster la version RandomizedSearchCV de clf (effectue une validation croisée pour nous, donc pas besoin d'utiliser un jeu de validation)rs_clf.fit(X_train, y_train);\n",
    "rs_clf.fit(X_train, y_train);\n",
    "\n",
    "# Arrétez le chronomètre\n",
    "end_time = time.time()\n",
    "print(f\"[INFO] Total time taken for {n_iter} random combinations of hyperparameters: {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque `RandomizedSearchCV` parcourt les combinaisons `n_iter` d'espace de recherche d'hyperparamètres, il stocke les meilleures dans l'attribut `best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trouvez les meilleurs hyperparamètres trouvés par RandomizedSearchCV\n",
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Désormais, lorsque nous appellerons `predict()` sur `rs_clf` (notre version `RandomizedSearchCV` de notre classificateur), il utilisera les meilleurs hyperparamètres qu'il a trouvés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 85.25%\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1 score: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Faites des prédictions avec les meilleurs hyperparamètres\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# Évaluez les prédictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce au test de « RandomizedSearchCV » sur un tas d'hyperparamètres différents, nous obtenons un bon coup de pouce à toutes les métriques d'évaluation de notre modèle de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Réglage des hyperparamètres avec [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "Il existe une autre façon dont nous pourrions essayer d’améliorer les hyperparamètres de notre modèle.\n",
    "\n",
    "Et c'est avec [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "La principale différence entre `GridSearchCV` et `RandomizedSearchCV` est que `GridSearchCV` recherche de manière exhaustive sur une grille d'hyperparamètres (il essaiera toutes les combinaisons possibles), tandis que `RandomizedSearchCV` recherche sur une grille d'hyperparamètres de manière aléatoire (en s'arrêtant après `n_iter` combinaisons).\n",
    "\n",
    "`GridSearchCV` fait également référence à un dictionnaire de distributions de paramètres sous forme de grille de paramètres (via le paramètre `param_grid`).\n",
    "\n",
    "Par exemple, regardons notre dictionnaire des hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['sqrt', 'log2', None],\n",
       " 'min_samples_split': [2, 4, 6, 8],\n",
       " 'min_samples_leaf': [1, 2, 4, 8]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RandomizedSearchCV` essaie des combinaisons `n_iter` de différentes valeurs.\n",
    "\n",
    "Alors que `GridSearchCV` essaiera toutes les combinaisons possibles.\n",
    "\n",
    "Et si vous vous souvenez de l'époque où nous avons fait le calcul : `max_degree` a 4 valeurs, `max_features` en a 2, `min_samples_leaf` en a 3, `min_samples_split` en a 3, `n_estimators` en a 5.\n",
    "\n",
    "Cela fait 4x2x3x3x5 = 360 modèles !\n",
    "\n",
    "Cela peut prendre beaucoup de temps en fonction de la puissance de l'ordinateur que vous utilisez, de la quantité de données dont vous disposez et de la complexité des hyperparamètres (généralement des valeurs plus élevées signifient un modèle plus complexe).\n",
    "\n",
    "Dans notre cas, les données que nous utilisons sont relativement petites (seulement environ 300 échantillons).\n",
    "\n",
    "Puisque nous avons déjà essayé de trouver des hyperparamètres idéaux en utilisant `RandomizedSearchCV`, nous allons créer une autre grille d'hyperparamètres basée sur les `best_params_` de `rs_clf` avec moins d'options, puis essayer d'utiliser `GridSearchCV` pour trouver un ensemble plus idéal. .\n",
    "\n",
    "Essentiellement, le flux de travail pourrait être :\n",
    "1. Ajustez les hyperparamètres à la main pour avoir une idée des données/du modèle.\n",
    "2. Créez un large ensemble de distributions d'hyperparamètres et recherchez-les de manière aléatoire avec `RandomizedSearchCV`.\n",
    "3. Trouvez les meilleurs hyperparamètres à partir de 2 et réduisez l'espace de recherche avant de rechercher de manière exhaustive un sous-ensemble plus petit avec `GridSearchCV`.\n",
    "\n",
    "> **Remarque :** Basé sur `best_params_` de `rs_clf`, cela implique que le prochain ensemble d'hyperparamètres que nous allons essayer se situe à peu près dans la même plage que le meilleur ensemble trouvé par `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une grille d'hyperparamètres similaire à rs_clf.best_params_\n",
    "param_grid = {\"n_estimators\": [200, 1000],\n",
    "              \"max_depth\": [30, 40, 50],\n",
    "              \"max_features\": [\"log2\"],\n",
    "              \"min_samples_split\": [2, 4, 6, 8],\n",
    "              \"min_samples_leaf\": [4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons créé une autre grille d'hyperparamètres sur lesquels effectuer la recherche, cette fois avec un total inférieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 combinations of hyperparameters to test.\n",
      "This is 60.0 times less than before (previous: 1440).\n"
     ]
    }
   ],
   "source": [
    "# Comptez le nombre total de combinaisons d'hyperparamètres à tester\n",
    "total_grid_search_hyperparameter_combinations_to_test = np.prod([len(value) for value in param_grid.values()])\n",
    "print(f\"There are {total_grid_search_hyperparameter_combinations_to_test} combinations of hyperparameters to test.\")\n",
    "print(f\"This is {total_randomized_hyperparameter_combintions_to_test/total_grid_search_hyperparameter_combinations_to_test} times less\\\n",
    " than before (previous: {total_randomized_hyperparameter_combintions_to_test}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, lorsque nous exécutons `GridSearchCV`, en lui transmettant notre classificateur (`clf`), la grille de paramètres (`param_grid`) et le nombre de plis de validation croisée que nous aimerions utiliser (`cv=5`), cela va créez un modèle avec chaque combinaison d'hyperparamètres, puis effectuez une validation croisée toutes les 5 fois (par exemple, 36 combinaisons d'hyperparamètres * 5 = 135 ajustements au total) et vérifiez les résultats.\n",
    "\n",
    "> **Remarque :** En fonction de la puissance de calcul de la machine que vous utilisez, l'exécution de la cellule suivante peut prendre quelques minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.7s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=6, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=8, n_estimators=1000; total time=   1.9s\n"
     ]
    }
   ],
   "source": [
    "# Démarrer le chronomètre\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Divisez en X & y\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Divisé en ensembles de train et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Définissez n_jobs sur -1 pour utiliser tous les cœurs de machine disponibles (si cela produit des erreurs, essayez n_jobs=1)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                      param_grid=param_grid,\n",
    "                      cv=5, # 5-fold cross-validation\n",
    "                      verbose=2) # affichez la progression\n",
    "\n",
    "# Ajuster la version RandomizedSearchCV de clf\n",
    "gs_clf.fit(X_train, y_train);\n",
    "\n",
    "# Trouver le temps d'exécution\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The total running time for running GridSearchCV was 148.36 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Combien de temps at-il fallu?\n",
    "total_time = end_time - start_time\n",
    "print(f\"[INFO] The total running time for running GridSearchCV was {total_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois terminé, nous pouvons vérifier les meilleures combinaisons d'hyperparamètres trouvées en utilisant l'attribut `best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifiez les meilleurs hyperparamètres trouvés avec GridSearchCV\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et par défaut, lorsque nous appellerons la fonction `predict()` sur `gs_clf`, elle utilisera les meilleurs hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.52%\n",
      "Precision: 0.88\n",
      "Recall: 0.91\n",
      "F1 score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.89, 'precision': 0.88, 'recall': 0.91, 'f1': 0.89}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prédictions maximales avec le classificateur GridSearchCV\n",
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# Évaluez les prédictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)\n",
    "gs_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons un DataFrame pour comparer les différentes métriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                                \"clf_2\": clf_2_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                \"grid search\": gs_metrics})\n",
    "compare_metrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir essayé de nombreuses combinaisons différentes d’hyperparamètres, nous obtenons une légère amélioration des résultats.\n",
    "\n",
    "Cependant, vous remarquerez parfois que vos résultats ne changent pas beaucoup.\n",
    "\n",
    "Ces choses pourraient arriver.\n",
    "\n",
    "Mais il est important de se rappeler que ce n’est pas fini. Il y a d'autres choses que vous pouvez essayer.\n",
    "\n",
    "Dans le sens du réglage des hyperparamètres, il pourrait y avoir un meilleur ensemble que nous pourrions trouver grâce à une recherche plus approfondie avec `RandomizedSearchCV` et `GridSearchCV`, cela nécessiterait plus d'expérimentation.\n",
    "\n",
    "Autres techniques que vous pourriez :\n",
    "* **Collecter davantage de données** - D'après les résultats obtenus actuellement par nos modèles, il semble qu'ils soient très capables de trouver des modèles. La collecte de davantage de données peut améliorer la capacité d'un modèle à trouver des modèles. Cependant, votre capacité à y parvenir dépendra largement du projet sur lequel vous travaillez.\n",
    "* **Essayez un modèle plus avancé** - Bien que notre modèle Random Forest optimisé fonctionne plutôt bien, une méthode d'ensemble plus avancée telle que [XGBoost](https://xgboost.ai/) ou [CatBoost](https:/ /catboost.ai/) pourrait mieux fonctionner. Je vais les laisser pour les activités extra-scolaires.\n",
    "\n",
    "Étant donné que l’apprentissage automatique relève à la fois de l’ingénierie et de la science, ce type d’expériences est courant dans tout projet d’apprentissage automatique.\n",
    "\n",
    "Maintenant que nous avons un modèle de forêt aléatoire optimisé, découvrons comment nous pouvons le sauvegarder et l'exporter afin de pouvoir le partager avec d'autres ou potentiellement l'utiliser dans une application externe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sauvegarde et chargement de modèles d'apprentissage automatique formés\n",
    "\n",
    "Notre modèle `GridSearchCV` (`gs_clf`) a les meilleurs résultats jusqu'à présent, nous allons l'exporter et l'enregistrer dans un fichier.\n",
    "\n",
    "### 6.1 Sauvegarde et chargement d'un modèle avec `pickle`\n",
    "\n",
    "Nous avons vu dès le début qu'une façon de sauvegarder un modèle consiste à utiliser le [module `pickle`](https://docs.python.org/3/library/pickle.html) de Python.\n",
    "\n",
    "Nous allons utiliser la méthode `dump()` de `pickle` et lui transmettre notre modèle, `gs_clf`, ainsi que la fonction `open()` contenant une chaîne pour le nom de fichier sous lequel nous voulons enregistrer notre modèle, ainsi que la chaîne `\"wb\"` qui signifie \"write binaire\", qui est le type de fichier `open()` sous lequel notre modèle sera écrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Enregistrer un modèle existant dans un fichier\n",
    "best_model_file_name_pickle = \"gs_random_forest_model_1.pkl\" # L'extension .pkl signifie \"pickle\"\n",
    "pickle.dump(gs_clf, open(best_model_file_name_pickle, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois enregistré, nous pouvons l'importer en utilisant la fonction `load()` de `pickle`, en lui passant `open()` contenant le nom du fichier sous forme de chaîne et `\"rb\"` signifiant \"lire binaire\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargez un modèle enregistré\n",
    "loaded_pickle_model = pickle.load(open(best_model_file_name_pickle, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que vous avez réimporté votre modèle entraîné à l'aide de « pickle », vous pouvez l'utiliser pour faire des prédictions comme d'habitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.52%\n",
      "Precision: 0.88\n",
      "Recall: 0.91\n",
      "F1 score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.89, 'precision': 0.88, 'recall': 0.91, 'f1': 0.89}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faire des prédictions et évaluer le modèle chargé\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test)\n",
    "loaded_pickle_model_metrics = evaluate_preds(y_test, pickle_y_preds)\n",
    "loaded_pickle_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous remarquerez que les métriques d'évaluation du modèle réimporté sont les mêmes que celles du modèle avant son exportation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pickle_model_metrics == gs_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Sauvegarde et chargement d'un modèle avec [`joblib`](https://joblib.readthedocs.io/en/latest/persistence.html)\n",
    "\n",
    "L'autre façon de charger et de sauvegarder des modèles est d'utiliser `joblib`. Ce qui fonctionne relativement de la même manière que « cornichon ».\n",
    "\n",
    "Pour enregistrer un modèle, nous pouvons utiliser la fonction `dump()` de `joblib`, en lui passant le modèle (`gs_clf`) et le nom de fichier souhaité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs_random_forest_model_1.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Enregistrer un modèle dans un fichier\n",
    "best_model_file_name_joblib = \"gs_random_forest_model_1.joblib\"\n",
    "dump(gs_clf, filename=best_model_file_name_joblib) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que vous avez enregistré un modèle en utilisant `dump()`, vous pouvez l'importer en utilisant `load()` et lui transmettre le nom de fichier du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer un modèle joblib enregistré\n",
    "loaded_joblib_model = load(filename=best_model_file_name_joblib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, une fois importé, nous pouvons faire des prédictions avec notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 88.52%\n",
      "Precision: 0.88\n",
      "Recall: 0.91\n",
      "F1 score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.89, 'precision': 0.88, 'recall': 0.91, 'f1': 0.89}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faire et évaluer des prédictions joblib\n",
    "joblib_y_preds = loaded_joblib_model.predict(X_test)\n",
    "loaded_joblib_model_metrics = evaluate_preds(y_test, joblib_y_preds)\n",
    "loaded_joblib_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et encore une fois, vous remarquerez que les mesures d’évaluation sont les mêmes qu’auparavant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_joblib_model_metrics == gs_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors, lequel devriez-vous utiliser, « pickle » ou « joblib » ?\n",
    "\n",
    "Selon la [documentation sur la persistance des modèles de Scikit-Learn](https://scikit-learn.org/stable/model_persistence.html), ils suggèrent qu'il pourrait être plus efficace d'utiliser `joblib` car il est plus efficace avec de grands tableaux numpy (qui est ce qui peut être contenu dans les modèles Scikit-Learn entraînés/ajustés)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Revisiter l'ensemble du pipeline\n",
    "\n",
    "Nous avons couvert beaucoup de choses. Et jusqu’à présent, cela semble être partout, ce qui est le cas.\n",
    "\n",
    "Mais ne vous inquiétez pas, les projets de machine learning commencent souvent ainsi.\n",
    "\n",
    "Tout un tas d'expérimentations et de code partout au début, puis une fois que vous avez trouvé quelque chose qui fonctionne, le processus de raffinement commence.\n",
    "\n",
    "À quoi ressemblerait ce processus de raffinement ?\n",
    "\n",
    "Nous utiliserons comme exemple le problème de régression des ventes de voitures (prédire le prix de vente des voitures).\n",
    "\n",
    "Pour ranger les choses, nous utiliserons la classe [`sklearn.pipeline.Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) de Scikit-Learn.\n",
    "\n",
    "Vous pouvez imaginer « Pipeline » comme étant un moyen d'enchaîner un certain nombre de processus Scikit-Learn différents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Création d'une régression [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "Vous vous souviendrez peut-être de l'époque où, dans la section 2 : Préparer les données, nous avons traité des données sur les ventes de voitures, pour construire un modèle de régression sur celles-ci, nous avons dû coder les caractéristiques catégorielles en nombres et remplir les données manquantes.\n",
    "\n",
    "Le code que nous avons utilisé fonctionnait, mais il était un peu partout.\n",
    "\n",
    "La bonne nouvelle est que « Pipeline » peut nous aider à le nettoyer.\n",
    "\n",
    "Rappelons à quoi ressemblent les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a 1 000 lignes, trois caractéristiques sont catégorielles (« Marque », « Couleur », « Portes »), les deux autres sont numériques (« Odomètre (KM) », « Prix ») et il y a 249 valeurs manquantes.\n",
    "\n",
    "Nous allons devoir transformer les caractéristiques catégorielles en nombres et remplir les valeurs manquantes avant de pouvoir ajuster un modèle.\n",
    "\n",
    "Nous allons construire un « Pipeline » pour ce faire.\n",
    "\n",
    "Le paramètre d'entrée principal de `Pipeline` est `steps` qui est une liste de tuples (`[(step_name, action_to_take)]`) du nom de l'étape, plus l'action que vous souhaitez qu'elle effectue.\n",
    "\n",
    "Dans notre cas, vous pourriez considérer les étapes comme suit :\n",
    "1. Remplissez les données manquantes\n",
    "2. Convertissez les données en nombres\n",
    "3. Construire un modèle sur les données\n",
    "\n",
    "Faisons-le!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Préparer les données\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# La modélisation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Configurer une graine aléatoire\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Importez des données et supprimez les lignes avec des étiquettes manquantes\n",
    "data = pd.read_csv(\"../data/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Définir différentes fonctionnalités et pipelines de transformateur\n",
    "categorical_features = [\"Make\", \"Colour\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "door_feature = [\"Doors\"]\n",
    "door_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))])\n",
    "\n",
    "numeric_features = [\"Odometer (KM)\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Configurer les étapes de prétraitement (remplir les valeurs manquantes, puis convertir en nombres)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "        (\"door\", door_transformer, door_feature),\n",
    "        (\"num\", numeric_transformer, numeric_features)])\n",
    "\n",
    "# Créer un pipeline de prétraitement et de modélisation\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                        (\"model\", RandomForestRegressor(n_jobs=-1))])\n",
    "\n",
    "# Fractionner les données\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Ajuster et marquer le modèle\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce que nous avons fait, c'est combiner une série d'étapes de prétraitement des données (remplissage des valeurs manquantes, codage des valeurs numériques) ainsi qu'un modèle dans un « Pipeline ».\n",
    "\n",
    "Cela nettoie non seulement le code, mais garantit également que les mêmes étapes sont suivies à chaque fois que le code est exécuté plutôt que d'avoir plusieurs étapes de traitement différentes à différentes étapes.\n",
    "\n",
    "Il est également possible d'utiliser `GridSearchCV` ou `RandomizedSearchCV` avec un `Pipeline`.\n",
    "\n",
    "La principale différence est que lors de la création d'une grille d'hyperparamètres, vous devez ajouter un préfixe à chaque hyperparamètre (voir la [documentation pour `RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble. RandomForestRegressor.html) pour une liste complète des hyperparamètres possibles à régler).\n",
    "\n",
    "Le préfixe est le nom de l'étape `Pipeline` que vous souhaitez modifier, suivi de deux traits de soulignement.\n",
    "\n",
    "Par exemple, pour ajuster les `n_estimators` de `\"model\"` dans le `Pipeline`, vous utiliseriez : `\"model__n_estimators\"` (notez le double trait de soulignement après `model__` au début).\n",
    "\n",
    "Voyons ça!\n",
    "\n",
    "> **Remarque :** En fonction de la puissance de traitement de votre ordinateur, l'exécution de la cellule ci-dessous peut prendre quelques minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.3s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.8s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=None, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median; total time=   0.2s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.7s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n",
      "[CV] END model__max_depth=5, model__max_features=sqrt, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median; total time=   1.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;)),\n",
       "                                                                                         (&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;Make&#x27;,\n",
       "                                                                          &#x27;Colour&#x27;]),\n",
       "                                                                        (&#x27;door&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;))]),\n",
       "                                                                         [&#x27;Doors&#x27;]),\n",
       "                                                                        (&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         [&#x27;Odometer &#x27;\n",
       "                                                                          &#x27;(KM)&#x27;])])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        RandomForestRegressor(n_jobs=-1))]),\n",
       "             param_grid={&#x27;model__max_depth&#x27;: [None, 5],\n",
       "                         &#x27;model__max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;model__min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;model__n_estimators&#x27;: [100, 1000],\n",
       "                         &#x27;preprocessor__num__imputer__strategy&#x27;: [&#x27;mean&#x27;,\n",
       "                                                                  &#x27;median&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;)),\n",
       "                                                                                         (&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;Make&#x27;,\n",
       "                                                                          &#x27;Colour&#x27;]),\n",
       "                                                                        (&#x27;door&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy=&#x27;constant&#x27;))]),\n",
       "                                                                         [&#x27;Doors&#x27;]),\n",
       "                                                                        (&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         [&#x27;Odometer &#x27;\n",
       "                                                                          &#x27;(KM)&#x27;])])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        RandomForestRegressor(n_jobs=-1))]),\n",
       "             param_grid={&#x27;model__max_depth&#x27;: [None, 5],\n",
       "                         &#x27;model__max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;model__min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;model__n_estimators&#x27;: [100, 1000],\n",
       "                         &#x27;preprocessor__num__imputer__strategy&#x27;: [&#x27;mean&#x27;,\n",
       "                                                                  &#x27;median&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Make&#x27;, &#x27;Colour&#x27;]),\n",
       "                                                 (&#x27;door&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=4,\n",
       "                                                                                 strategy=&#x27;constant&#x27;))]),\n",
       "                                                  [&#x27;Doors&#x27;]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;Odometer (KM)&#x27;])])),\n",
       "                (&#x27;model&#x27;, RandomForestRegressor(n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Make&#x27;, &#x27;Colour&#x27;]),\n",
       "                                (&#x27;door&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=4,\n",
       "                                                                strategy=&#x27;constant&#x27;))]),\n",
       "                                 [&#x27;Doors&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
       "                                 [&#x27;Odometer (KM)&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Make&#x27;, &#x27;Colour&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">door</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Doors&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=4, strategy=&#x27;constant&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Odometer (KM)&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('onehot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Make',\n",
       "                                                                          'Colour']),\n",
       "                                                                        ('door',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value=4,\n",
       "                                                                                                        strategy='constant'))]),\n",
       "                                                                         ['Doors']),\n",
       "                                                                        ('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         ['Odometer '\n",
       "                                                                          '(KM)'])])),\n",
       "                                       ('model',\n",
       "                                        RandomForestRegressor(n_jobs=-1))]),\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': ['sqrt'],\n",
       "                         'model__min_samples_split': [2, 4],\n",
       "                         'model__n_estimators': [100, 1000],\n",
       "                         'preprocessor__num__imputer__strategy': ['mean',\n",
       "                                                                  'median']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilisation de la recherche par grille avec pipeline\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"], # notez le double trait de soulignement après chaque préfixe \"preprocessor__\"\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"sqrt\"],\n",
    "    \"model__min_samples_split\": [2, 4]\n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trouvons maintenant le score de notre modèle (par défaut `GridSearchCV` enregistre le meilleur modèle dans l'objet `gs_model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2848784564026805"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notez le meilleur modèle\n",
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant `GridSearchCV`, nous constatons une belle augmentation du score de nos modèles.\n",
    "\n",
    "Et le meilleur, c'est que, comme tout est dans un « Pipeline », nous pourrions facilement reproduire ces résultats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c556f6eb84b27a92005489cdcf9c9b80cc62ee891441f20eabfc5ad7282165a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
